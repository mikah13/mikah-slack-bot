'use strict';

Object.defineProperty(exports, "__esModule", {
  value: true
});

var _keys = require('babel-runtime/core-js/object/keys');

var _keys2 = _interopRequireDefault(_keys);

var _apply = require('babel-runtime/core-js/reflect/apply');

var _apply2 = _interopRequireDefault(_apply);

var _promise = require('babel-runtime/core-js/promise');

var _promise2 = _interopRequireDefault(_promise);

var _isObject2 = require('lodash/isObject');

var _isObject3 = _interopRequireDefault(_isObject2);

var _isBoolean2 = require('lodash/isBoolean');

var _isBoolean3 = _interopRequireDefault(_isBoolean2);

var _debounce2 = require('lodash/debounce');

var _debounce3 = _interopRequireDefault(_debounce2);

var _ampersandState = require('ampersand-state');

var _ampersandState2 = _interopRequireDefault(_ampersandState);

var _webrtc = require('./webrtc');

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

// at some point, this could potentially move into webrtc.js, but it gets the
// job done for now.
var sending = {
  audio: {
    start: _webrtc.startSendingAudio,
    stop: _webrtc.stopSendingAudio
  },
  video: {
    start: _webrtc.startSendingVideo,
    stop: _webrtc.stopSendingVideo
  }
};

/**
 * Determines if the peer connection is receiving the specified kind of media
 * @param {string} kind audio|video
 * @param {RTCPeerConnection} pc
 * @private
 * @returns {bool} true if receiving, false if not
 */
function getRemoteMediaStatus(kind, pc) {
  if (pc.signalingState === 'closed') {
    return false;
  }

  var streams = pc.getRemoteStreams();

  if (streams.length === 0) {
    return false;
  }

  var res = streams.reduce(function (areStreamsFlowing, stream) {
    var tracks = stream.getTracks().filter(function (track) {
      return track.kind === kind;
    });

    if (tracks.length === 0) {
      return false;
    }

    return tracks.reduce(function (isTrackReceiving, track) {
      if (isTrackReceiving) {
        return isTrackReceiving;
      }

      if (track.readyState === 'ended') {
        return false;
      }

      if (track.ended) {
        return false;
      }

      return true;
    }, undefined);
  }, undefined);

  if (res) {
    return res;
  }

  return false;
}

/**
 * Determines if the peer connection is sending the specified kind of media
 * @param {string} kind audio|video
 * @param {RTCPeerConnection} pc
 * @private
 * @returns {bool} true if sending, false if not
 */
function getLocalMediaStatus(kind, pc) {
  var res = pc.getLocalStreams().reduce(function (isFlowing, stream) {
    var isStreamFlowing = stream.getTracks().reduce(function (isFlowingForTracks, track) {
      var isTrackFlowing = track.kind === kind && track.enabled;
      return isFlowingForTracks || isTrackFlowing;
    }, false);
    return isFlowing || isStreamFlowing;
  }, false);
  return res;
}

var WebRTCMedia = _ampersandState2.default.extend({
  props: {
    audio: {
      default: false,
      type: 'boolean'
    },
    audioConstraint: 'any',
    ended: {
      default: false,
      type: 'boolean'
    },
    localMediaStream: {
      default: undefined,
      type: 'object'
    },
    offerToReceiveAudio: {
      default: false,
      type: 'boolean'
    },
    offerToReceiveVideo: {
      default: false,
      type: 'boolean'
    },
    receivingAudio: {
      default: false,
      type: 'boolean'
    },
    receivingVideo: {
      default: false,
      type: 'boolean'
    },
    remoteMediaStream: {
      default: undefined,
      type: 'object'
    },
    sendingAudio: {
      default: false,
      type: 'boolean'
    },
    sendingVideo: {
      default: false,
      type: 'boolean'
    },
    video: {
      default: false,
      type: 'boolean'
    },
    videoConstraint: 'any'
  },

  session: {
    answerSdp: 'string',
    offerSdp: 'string',
    peer: {
      type: 'object'
    }
  },

  acceptAnswer: function acceptAnswer(answer) {
    var _this = this;

    return (0, _webrtc.acceptAnswer)(this.peer, answer).then(function () {
      _this.answerSdp = answer;
      _this.set({
        sendingAudio: getLocalMediaStatus('audio', _this.peer),
        sendingVideo: getLocalMediaStatus('video', _this.peer)
      });
    }).then(function () {
      return _this.trigger('answeraccepted');
    });
  },
  createOffer: function createOffer() {
    var _this2 = this;

    if (!this.peer) {
      this.peer = new RTCPeerConnection({ iceServers: [] });

      this.peer.ontrack = function (event) {
        _this2.remoteMediaStream = event.streams[0];

        _this2.remoteMediaStream.getTracks().forEach(function (track) {
          track.onended = function () {
            try {
              if (track.kind === 'audio') {
                _this2.receivingAudio = getRemoteMediaStatus('audio', _this2.peer);
              } else {
                _this2.receivingVideo = getRemoteMediaStatus('video', _this2.peer);
              }
            } catch (e) {
              _this2.emit('error', e);
            }
          };
        });

        _this2.receivingAudio = getRemoteMediaStatus('audio', _this2.peer);
        _this2.receivingVideo = getRemoteMediaStatus('video', _this2.peer);
      };
    }

    var p = void 0;
    if (this.localMediaStream) {
      p = _promise2.default.resolve();
    } else if (this.audio || this.video) {
      p = _promise2.default.resolve((0, _webrtc.getUserMedia)({
        audio: this.audioConstraint,
        video: this.videoConstraint
      }).then(function (stream) {
        _this2.localMediaStream = stream;
      }));
    }

    return _promise2.default.resolve(p).then(function () {
      if (_this2.localMediaStream && !_this2.peer.getLocalStreams().includes(_this2.localMediaStream)) {
        (0, _webrtc.addStream)(_this2.peer, _this2.localMediaStream);
      }
    }).then(function () {
      return (0, _webrtc.createOffer)(_this2.peer, {
        offerToReceiveAudio: _this2.offerToReceiveAudio,
        offerToReceiveVideo: _this2.offerToReceiveVideo
      });
    }).then((0, _webrtc.ensureH264)(this.video)).then(function (sdp) {
      _this2.bindNegotiationEvents();
      _this2.offerSdp = sdp;
      return sdp;
    });
  },
  end: function end() {
    if (!this.ended) {
      if (this.peer && this.peer.signalingState !== 'closed') {
        (0, _webrtc.end)(this.peer);
      }
      this.unset('localMediaStream');
      this.unset('remoteMediaStream');
      this.ended = true;
    }
  },
  initialize: function initialize() {
    var _this3 = this;

    for (var _len = arguments.length, args = Array(_len), _key = 0; _key < _len; _key++) {
      args[_key] = arguments[_key];
    }

    (0, _apply2.default)(_ampersandState2.default.prototype.initialize, this, args);

    ['audio', 'video'].forEach(function (mediaType) {
      _this3.on('change:' + mediaType, function () {
        if (!_this3.peer) {
          return;
        }

        var p = void 0;
        if (_this3[mediaType]) {
          var hasTrack = _this3.localMediaStream.getTracks()
          // I really don't see a more readable way to implement this
          // eslint-disable-next-line max-nested-callbacks
          .filter(function (track) {
            return track.kind === mediaType;
          }).length;

          if (hasTrack) {
            p = sending[mediaType].start(_this3.peer);
          } else {
            p = new _promise2.default(function (resolve) {
              // I really don't see a more readable way to implement this
              // eslint-disable-next-line max-nested-callbacks
              _this3.once('negotiationneeded', function () {
                _this3.once('answeraccepted', resolve);
              });
            });
            sending[mediaType].start(_this3.peer);
          }
        } else {
          p = sending[mediaType].stop(_this3.peer);
        }

        _promise2.default.resolve(p).then(function () {
          _this3[mediaType === 'audio' ? 'sendingAudio' : 'sendingVideo'] = getLocalMediaStatus(mediaType, _this3.peer);
        }).catch(function (reason) {
          _this3.emit('error', reason);
        });
      });
    });

    this.on('change:localMediaStream', function () {
      if (!_this3.peer) {
        return;
      }

      if (_this3.peer.signalingState === 'closed') {
        return;
      }

      var streams = _this3.peer.getLocalStreams();
      if (!streams.includes(_this3.localMediaStream)) {
        streams.forEach(function (stream) {
          (0, _webrtc.removeStream)(_this3.peer, stream);
        });
        (0, _webrtc.addStream)(_this3.peer, _this3.localMediaStream);

        var sendingAudio = getLocalMediaStatus('audio', _this3.peer);
        var sendingVideo = getLocalMediaStatus('video', _this3.peer);
        _this3.set({
          sendingAudio: sendingAudio,
          audio: sendingAudio,
          sendingVideo: sendingVideo,
          video: sendingVideo
        });
      }
    });
  },


  /**
   * Binds events that should be bound one time only once the session has been
   * fully negotiated
   * @private
   * @returns {undefined}
   */
  bindNegotiationEvents: function bindNegotiationEvents() {
    var _this4 = this;

    if (this.bound) {
      return;
    }
    this.bound = true;

    this.peer.onnegotiationneeded = (0, _debounce3.default)(function () {
      _this4.emit('negotiationneeded');
    });

    this.on('change:offerToReceiveAudio', function () {
      _this4.trigger('negotiationneeded');
    });

    this.on('change:offerToReceiveVideo', function () {
      _this4.trigger('negotiationneeded');
    });
  },
  set: function set(key, value, options) {
    var attrs = void 0;
    // Handle both `"key", value` and `{key: value}` -style arguments.
    if ((0, _isObject3.default)(key) || key === null) {
      attrs = key;
      options = value;
    } else {
      attrs = {};
      attrs[key] = value;
    }

    options = options || {};

    (0, _keys2.default)(attrs).forEach(function (k) {
      ['audio', 'video'].forEach(function (mediaType) {
        if (k === mediaType) {
          if ((0, _isObject3.default)(attrs[k])) {
            attrs[mediaType + 'Constraint'] = attrs[k];
            attrs[k] = true;
          } else if ((0, _isBoolean3.default)(attrs[k])) {
            attrs[mediaType + 'Constraint'] = attrs[k];
          }
        }
      });
    });

    (0, _apply2.default)(_ampersandState2.default.prototype.set, this, [attrs, options]);
  }
});

exports.default = WebRTCMedia;